{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/fr7g30_x5x12d68ww_s6w2_m0000gn/T/ipykernel_7598/3296619640.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = dict()\n",
    "for elem in glob.glob(f\"/Users/melloo21/Desktop/NUS Items/CS4220/cs4220_projects/data/feature_set/*_final_final.pickle\"):\n",
    "    key = elem.split(\"/\")[-1].split(\".\")[0].split(\"_final_final\")[0]\n",
    "    with open(f'{elem}', 'rb') as handle:\n",
    "        all_dfs[key] = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['median_input', 'POS_IDX', 'y_label'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs['feature_set_syn2'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_key_join = ['feature_set_syn2', 'feature_set_syn1', 'feature_set_real1', 'feature_set_syn4', 'feature_set_syn5', 'feature_set_syn3']\n",
    "# list_key_join = ['feature_set_syn2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10785, 31)\n",
      "(8805, 31)\n",
      "(3270, 31)\n",
      "(38480, 31)\n",
      "(3830, 31)\n",
      "(19417, 31)\n"
     ]
    }
   ],
   "source": [
    "# Rejoining dataframes\n",
    "all_dataset = dict()\n",
    "total_rows = 0\n",
    "for keys in list_key_join:\n",
    "    # Adding flag \n",
    "    df = pd.concat([all_dfs[keys][\"median_input\"],all_dfs[keys][\"y_label\"]], axis=1)\n",
    "    if \"syn\" in keys:\n",
    "        df[\"is_syn\"] = 1\n",
    "    else:\n",
    "        df[\"is_syn\"] = 0\n",
    "\n",
    "    all_dataset[keys] = df\n",
    "    total_rows += df.shape[0]\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(all_dataset.values(), ignore_index=True)\n",
    "\n",
    "assert all_df.shape[0] == total_rows, \"DF generated does not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FILTER_Mutect2', 'FILTER_Freebayes', 'FILTER_Vardict',\n",
       "       'FILTER_Varscan', 'm2_MQ', 'm2_FS', 'm2_MQ0', 'm2_MQRankSum', 'm2_NLOD',\n",
       "       'f_MQMR', 'f_MQM', 'f_AB', 'f_ABP', 'f_MEANALT', 'f_ODDS', 'f_PAIRED',\n",
       "       'f_PAIREDR', 'f_QR', 'f_RPP', 'vs_DP', 'vs_GPV', 'vs_SPV', 'vs_SSC',\n",
       "       'vd_AF', 'vd_DP', 'vd_MSI', 'vd_SOR', 'vd_SSF', 'vd_VD', 'is_snv',\n",
       "       'is_syn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = {\n",
    "    \"median_input\": all_df.drop(columns=\"is_snv\"),\n",
    "    \"y_label\" : all_df[[\"is_snv\"]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved combined_dataset\n"
     ]
    }
   ],
   "source": [
    "# Save Pickle file\n",
    "filepath = \"/Users/melloo21/Desktop/NUS Items/CS4220/cs4220_projects/data/feature_set\"\n",
    "feature_filename =f\"combined_dataset\"\n",
    "with open(f'{filepath}/{feature_filename}.pickle', 'wb') as handle:\n",
    "    pickle.dump(feature_set, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(f\"saved {feature_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
